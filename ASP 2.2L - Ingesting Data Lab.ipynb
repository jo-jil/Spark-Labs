{"cells":[{"cell_type":"markdown","source":["# Ingesting Data Lab\n\nRead in CSV files containing products data.\n\n##### Tasks\n1. Read with infer schema\n2. Read with user-defined schema\n3. Read with schema as DDL formatted string\n4. Write using Delta format"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7b38701-b6b4-4896-a18e-6a1d7a0678df","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aea967ce-4c1b-4eb2-b3e9-e3ec02bbf240","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\n\nValidating the locally installed datasets...(3 seconds)\n\nCreating & using the schema \"da_lpalum_7163_asp\"...(1 seconds)\n\nPredefined tables in \"da_lpalum_7163_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks/database.db\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 5 seconds\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\n\nValidating the locally installed datasets...(3 seconds)\n\nCreating & using the schema \"da_lpalum_7163_asp\"...(1 seconds)\n\nPredefined tables in \"da_lpalum_7163_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks/database.db\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 5 seconds\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1. Read with infer schema\n- View the first CSV file using DBUtils method **`fs.head`** with the filepath provided in the variable **`single_product_cs_file_path`**\n- Create **`products_df`** by reading from CSV files located in the filepath provided in the variable **`products_csv_path`**\n  - Configure options to use first line as header and infer schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"82acc305-0ceb-41ef-b976-1e507dc3fb3c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\nsingle_product_csv_file_path = f\"{DA.paths.datasets}/products/products.csv/part-00000-tid-1663954264736839188-daf30e86-5967-4173-b9ae-d1481d3506db-2367-1-c000.csv\"\nprint(dbutils.fs.head(single_product_csv_file_path))\n\nproducts_csv_path = f\"{DA.paths.datasets}/products/products.csv\"\nproducts_df = (spark\n               .read\n               .option(\"header\", True)\n               .option(\"inferSchema\", True)\n               .csv(products_csv_path)\n              )\n\nproducts_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b2552d3-26cf-46e0-9984-9af9b061a225","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"item_id,name,price\nM_PREM_Q,Premium Queen Mattress,1795.0\nM_STAN_F,Standard Full Mattress,945.0\nM_PREM_F,Premium Full Mattress,1695.0\n\nroot\n |-- item_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["item_id,name,price\nM_PREM_Q,Premium Queen Mattress,1795.0\nM_STAN_F,Standard Full Mattress,945.0\nM_PREM_F,Premium Full Mattress,1695.0\n\nroot\n |-- item_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**1.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a496b49a-3292-4bdc-b02e-4c1e879245fd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["assert(products_df.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"31df2a45-5f32-4cba-8e98-234f84e08bec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Read with user-defined schema\nDefine schema by creating a **`StructType`** with column names and data types"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3194e552-29c1-4857-9d28-d45ca7033941","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\nfrom pyspark.sql.types import DoubleType, StringType, StructType, StructField\n\nuser_defined_schema = StructType([\n    StructField(\"item_id\", StringType(), True),\n    StructField(\"name\", StringType(), True),\n    StructField(\"price\", DoubleType(), True)\n])\n\nproducts_df2 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(user_defined_schema)\n                .csv(products_csv_path)\n               )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45e68bb2-8ce1-4395-9152-ad7ef10dae4c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**2.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"caab2dc0-4c84-4995-9aee-5699dfadb3f3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["assert(user_defined_schema.fieldNames() == [\"item_id\", \"name\", \"price\"])\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e2f5f76d-b920-4238-850e-362b6d83ecc3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row\n\nexpected1 = Row(item_id=\"M_STAN_Q\", name=\"Standard Queen Mattress\", price=1045.0)\nresult1 = products_df2.first()\n\nassert(expected1 == result1)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68041dd9-2c59-4b7e-b69c-2ec728cf8d2a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Read with DDL formatted string"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"40d8a850-4170-4693-88e7-6a8b7d397f30","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\nddl_schema = \"`item_id` STRING,`name` STRING,`price` DOUBLE\"\n\nproducts_df3 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(ddl_schema)\n                .csv(products_csv_path)\n               )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"620942ea-3055-496b-9b1f-cacb98084a0e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**3.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"858b95f5-b02d-4954-adfe-ce122653f029","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["assert(products_df3.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9d426415-7fb6-46f9-9fea-b6fe94b37801","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4. Write to Delta\nWrite **`products_df`** to the filepath provided in the variable **`products_output_path`**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27ec9202-173b-4a74-8c5b-ffab7e0bf02a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\nproducts_output_path = f\"{DA.paths.working_dir}/delta/products\"\n(products_df\n .write\n .format(\"delta\")\n .mode(\"overwrite\")\n .save(products_output_path)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1bceaf2d-479e-4932-97e7-1b9810d4bd1b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**4.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b875f1a-b872-42c2-81c6-7895f78a4958","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["verify_files = dbutils.fs.ls(products_output_path)\nverify_delta_format = False\nverify_num_data_files = 0\nfor f in verify_files:\n    if f.name == \"_delta_log/\":\n        verify_delta_format = True\n    elif f.name.endswith(\".parquet\"):\n        verify_num_data_files += 1\n\nassert verify_delta_format, \"Data not written in Delta format\"\nassert verify_num_data_files > 0, \"No data written\"\ndel verify_files, verify_delta_format, verify_num_data_files\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e49feb7b-842b-43b9-abfa-c86caebcb71d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5767d289-a937-4f3c-baae-e6ab8bfb9df2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["DA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"32c3a91c-14bd-40fa-a656-64e36eede3b6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Resetting the learning environment...\n...dropping the schema \"da_lpalum_7163_asp\"...(0 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks\"...(1 seconds)\n\n\nValidating the locally installed datasets...(3 seconds)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Resetting the learning environment...\n...dropping the schema \"da_lpalum_7163_asp\"...(0 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/lpalum@ur.rochester.edu/apache-spark-programming-with-databricks\"...(1 seconds)\n\n\nValidating the locally installed datasets...(3 seconds)\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.2L - Ingesting Data Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":153415606858950}},"nbformat":4,"nbformat_minor":0}
